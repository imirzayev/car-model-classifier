{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 17:22:34.760367: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-02 17:22:34.760384: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from model import TransferModel\n",
    "\n",
    "from keras.optimizers import adam_v2\n",
    "from keras import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "INPUT_DATA_DIR = 'color'\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "TARGET_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "TARGET = 'model'\n",
    "BASE = 'ResNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "train_data = train_datagen.flow_from_directory(directory=INPUT_DATA_DIR, batch_size=BATCH_SIZE, target_size=TARGET_SIZE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 17:22:42.862615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-02 17:22:42.862636: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-02 17:22:42.862651: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ilham): /proc/driver/nvidia/version does not exist\n",
      "2022-03-02 17:22:42.862764: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50V2(include_top=False, input_shape=INPUT_SHAPE, weights=None)\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_base = base_model.output\n",
    "add_to_base = GlobalAveragePooling2D(data_format='channels_last', name='head_gap')(add_to_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = Dense(len(train_data), activation='softmax', name='head_pred')(add_to_base)\n",
    "com_model = Model(base_model.input, new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_model.compile(loss='categorical_crossentropy', optimizer=adam_v2.Adam(0.0001), metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 17:22:50.658782: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2022-03-02 17:22:50.741506: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 106463232 exceeds 10% of free system memory.\n",
      "2022-03-02 17:22:50.808714: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2022-03-02 17:22:50.914383: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2022-03-02 17:22:50.966562: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 14s 3s/step - loss: 1.2402 - categorical_accuracy: 0.4225\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.9863 - categorical_accuracy: 0.5493\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.6650 - categorical_accuracy: 0.8592\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.5528 - categorical_accuracy: 0.9014\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.3996 - categorical_accuracy: 0.9437\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.2801 - categorical_accuracy: 0.9577\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.2132 - categorical_accuracy: 0.9577\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 12s 5s/step - loss: 0.1448 - categorical_accuracy: 0.9577\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 12s 5s/step - loss: 0.1127 - categorical_accuracy: 0.9859\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.0479 - categorical_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 12s 5s/step - loss: 0.0405 - categorical_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.0292 - categorical_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.0370 - categorical_accuracy: 0.9859\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.0078 - categorical_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 13s 3s/step - loss: 0.0056 - categorical_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.0053 - categorical_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 12s 3s/step - loss: 0.0041 - categorical_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 13s 6s/step - loss: 0.0048 - categorical_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 12s 6s/step - loss: 0.0060 - categorical_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 13s 6s/step - loss: 0.0015 - categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = com_model.fit(train_data, epochs=20, steps_per_epoch=(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcom_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest/94.png\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/License Plate/car-model-classifier/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/License Plate/car-model-classifier/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:902\u001B[0m, in \u001B[0;36mTensorShape.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    901\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_v2_behavior:\n\u001B[0;32m--> 902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dims\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mvalue\n\u001B[1;32m    903\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    904\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dims[key]\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "com_model.predict('test/94.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.47581592, 0.19572717, 0.32845694], dtype=float32)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img('test/138.png', target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "img /= 255.0\n",
    "img = img.reshape(-1, *img.shape)\n",
    "pred = com_model.predict(img)\n",
    "classes = os.listdir('color')\n",
    "pred[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26d3cea84d59421de305541ac77befe02f85418d4818d56efd55dfda309af7b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}